{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Speeding up Science \u00b6 \"Speeding up Science\" is a series of workshops focused on developing application-specific Jupyter notebooks which are executable/launchable via Binder. The goal of these workshops is to \u201creverse engineer\u201d common data visualization approaches used for biological data analysis and commonly published in scientific journal articles (heatmaps, read/OTU summaries, etc.). Workshop goals/products include: Compile reproducible code workflows for the three common environmental -Omics approaches (metabarcoding, metagenomics, or metatranscriptomics). Jupyter notebooks will contain functional code and customizable parameters (with documentation/explanation) that users can adapt and deploy on their own data sets, assuming import of \u201cstandard\u201d data formats that are typically generated during standard -Omics pipelines (e.g. FASTQ files of reads/contigs, OTU tables for metabarcoding). Gather information from end users in the life sciences about their computational needs and ongoing challenges. Where do the gaps exist in terms of your data analysis needs? Where do existing tools, pipelines, tutorials and trainings fall short? Lay the foundations for new open-source online lessons focused on \u201canalyze your own data\u201d training (where participants come to a workshop to specifically learn to analyze their own in-hand environmental -Omics datasets). The first workshop happedn May 8-10, 2019 at UC Davis, and produced a number of analysis and visualization notebooks for metagenomics, metatranscriptomics, and metabarcoding. A static version of these workflows can be viewed on this site, and each workflow contains a link to an executable version hosted on Binder. You can find us on twitter at #SpeedingUpScience","title":"Home"},{"location":"#speeding-up-science","text":"\"Speeding up Science\" is a series of workshops focused on developing application-specific Jupyter notebooks which are executable/launchable via Binder. The goal of these workshops is to \u201creverse engineer\u201d common data visualization approaches used for biological data analysis and commonly published in scientific journal articles (heatmaps, read/OTU summaries, etc.). Workshop goals/products include: Compile reproducible code workflows for the three common environmental -Omics approaches (metabarcoding, metagenomics, or metatranscriptomics). Jupyter notebooks will contain functional code and customizable parameters (with documentation/explanation) that users can adapt and deploy on their own data sets, assuming import of \u201cstandard\u201d data formats that are typically generated during standard -Omics pipelines (e.g. FASTQ files of reads/contigs, OTU tables for metabarcoding). Gather information from end users in the life sciences about their computational needs and ongoing challenges. Where do the gaps exist in terms of your data analysis needs? Where do existing tools, pipelines, tutorials and trainings fall short? Lay the foundations for new open-source online lessons focused on \u201canalyze your own data\u201d training (where participants come to a workshop to specifically learn to analyze their own in-hand environmental -Omics datasets). The first workshop happedn May 8-10, 2019 at UC Davis, and produced a number of analysis and visualization notebooks for metagenomics, metatranscriptomics, and metabarcoding. A static version of these workflows can be viewed on this site, and each workflow contains a link to an executable version hosted on Binder. You can find us on twitter at #SpeedingUpScience","title":"Speeding up Science"},{"location":"LDA/","text":"```{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE) ```{r} library(phyloseq) library('topicmodels') library('reshape2') library('dplyr') library('bbmle') library('ggplot2') library('tidytext') library('data.table') install.packages('topicmodels', dependencies=TRUE, repos='http://cran.rstudio.com/') install.packages(\"topicmodels\") otu_table <- read.csv ( \"count_table.csv\" , sep = \",\" , row.names = 1 ) otu_table <- as.matrix ( otu_table ) otu_table taxa <- read.csv ( \"taxa_function.csv\" , sep = \",\" , row.names = 1 ) otu <- otu_table ( otu_table , taxa_are_rows = TRUE ) taxa <- as.matrix ( taxa ) tax <- tax_table ( taxa ) physeq <- merge_phyloseq ( tax , otu ) otu_table ( physeq ) rank_names ( physeq ) melt <- psmelt ( physeq ) write.csv ( melt , \"melt.csv\" ) #load genus level microbiom data ptarmiganGenus <- read.csv ( \"melt.csv\" ) # genus level resolution of microbiome head ( ptarmiganGenus ) #convert from long to wide format ptarmiganGenus2 <- dcast ( ptarmiganGenus , Sample ~ Genus , value.var = \"Abundance\" ) #query Stephanie on sample id's unique ( ptarmiganGenus2 $ Sample ) #IMPORTANT TO CLIP RECORDS TO EXCLUDE NON-MICROBE GENETIC INFORMATION ##format data ptarmiganGenus3 <- ptarmiganGenus2[ , -1 ] #drop sample id rownames ( ptarmiganGenus3 ) <- ptarmiganGenus2[ , 1 ] #drop rows/sites that sum to zero = no fish recorded ptarmiganGenus3 $ sum <- rowSums ( ptarmiganGenus3 ) ptarmiganGenus3 <- ptarmiganGenus3 %>% filter ( sum > 0 ) %>% select ( - c ( sum )) VEM2 = LDA ( ptarmiganGenus3 , k = 2 , control = list ( seed = 240444 )) #fit model with 2 communities library ( ggplot2 ) plot_beta ( VEM2 , prob = 0.01 ) plot_gamma ( VEM2 , lls ) VEM3 = LDA ( ptarmiganGenus3 , k = 3 , control = list ( seed = 240444 )) #fit model with 3 communities VEM4 = LDA ( ptarmiganGenus3 , k = 4 , control = list ( seed = 240444 )) #fit model with 4 communities VEM5 = LDA ( ptarmiganGenus3 , k = 5 , control = list ( seed = 240444 )) #fit model with 5 communities VEM6 = LDA ( ptarmiganGenus3 , k = 6 , control = list ( seed = 240444 )) #fit model with 6 communities VEM7 = LDA ( ptarmiganGenus3 , k = 7 , control = list ( seed = 240444 )) #fit model with 6 communities # model selection for the optimal # communities identified AICtab ( VEM3 , VEM2 , VEM4 , VEM5 , VEM6 , VEM7 ) # 5 communities results in the best model fit #get parameter estimates z = posterior ( VEM2 ) z $ topics commun.plot = as.data.frame ( z $ topics ) #community proportions in each sample bird str ( commun.plot ) commun.plot commun.plot $ Samples <- ptarmiganGenus2 $ Sample commun.plot $ Samples commun.spp = z $ terms #probability of a species belonging to a community commun.spp # look at the specific assignment of species to a community ap_lda_td <- data.table ( tidy ( VEM2 )) ap_lda_td nrow ( ap_lda_td[topic == 2 ] ) ap_lda_td ap_top_terms <- ap_lda_td %>% group_by ( topic ) %>% top_n ( 10 , beta ) %>% ungroup () %>% arrange ( topic , - beta ) ap_top_terms ap_top_terms %>% mutate ( term = reorder ( term , beta )) %>% ggplot ( aes ( term , beta , fill = factor ( topic ))) + geom_bar ( stat = \"identity\" , show.legend = FALSE ) + facet_wrap ( ~ topic , scales = \"free\" ) + coord_flip () library ( ggplot2 ) plot_beta ( beta , prob = 0.01 ) install.packages ( \"topicmodels\" ) library ( slam ) library ( topicmodels ) dtm = as.simple_triplet_matrix ( data.final ) seed_num = 2014 fold_num = 5 kv_num = c ( 2 : 30 ) sp = smp ( cross = fold_num , n = nrow ( dtm ), seed = seed_num ) control = list ( seed = seed_num , burnin = 1000 , thin = 100 , iter = 1000 ) #not run: system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp,method='Gibbs',control=control))) #not run: plot_perplexity(ctmK,kv_num)","title":"LDA Analysis"},{"location":"MAGstats/","text":"MAGstats \u00b6 A workflow to visualize the completeness and redundancy of your MAGs. Beginners Guide \u00b6 To visualize the completeness and reduduancy of your MAG, you need to get two files ready ( example_data ): A newick tree file ( MAG_tree.nwk ) A metadata file ( MAG_metadata.tsv ) The metadata file must contain these columns in order: MAG_ID Length Completion Redundancy GC_Content , and is tab-delimited. You can launch this jupyter notebook using binder by clicking , and upload your files to the example_data folder via the upload button in your project directory (where the index.ipynb locates). You probably need to modify these two lines to adapt to your file names in the first code block before running through all the codes: nwk_file <- \"MAG_tree.nwk\" bin_metadata_file <- \"MAG_metadata.tsv\" How to generate input files \u00b6 For the tree file, you can use GToTree to extract single-copy marker genes and to get the concatenated multiple sequence alignements. Then use RAxML-NG to build the maximum-likelihood phylogenomic tree. GToTree also generate a tree file by running fasttree . For the metadata file, you can get it via checkM or anvio , and format it using Excel and export it as tsv. If everything works well, you will get something like this: Read in MAG tree \u00b6 data_folder <- \"./example_data\" nwk_file <- \"MAG_tree.nwk\" bin_metadata_file <- \"MAG_metadata.tsv\" path2nwk_file <- paste ( data_folder , nwk_file , sep = \"/\" ) path2metadata_file <- paste ( data_folder , bin_metadata_file , sep = \"/\" ) path2nwk_file path2metadata_file './example_data/MAG_tree.nwk' './example_data/MAG_metadata.tsv' load packages \u00b6 library ( \"RColorBrewer\" ) library ( 'ggplot2' ) library ( 'ggtree' ) ggtree v1.14.6 For help: https://guangchuangyu.github.io/software/ggtree If you use ggtree in published research, please cite the most appropriate paper(s): - Guangchuang Yu, David Smith, Huachen Zhu, Yi Guan, Tommy Tsan-Yuk Lam. ggtree: an R package for visualization and annotation of phylogenetic trees with their covariates and other associated data. Methods in Ecology and Evolution 2017, 8(1):28-36, doi:10.1111/2041-210X.12628 - Guangchuang Yu, Tommy Tsan-Yuk Lam, Huachen Zhu, Yi Guan. Two methods for mapping and visualizing associated data on phylogeny using ggtree. Molecular Biology and Evolution 2018, accepted. doi: 10.1093/molbev/msy194 read in tree \u00b6 tree <- read.tree ( path2nwk_file ) str ( tree ) List of 5 $ edge : int [1:200, 1:2] 102 103 103 104 104 102 105 106 107 108 ... $ edge.length: num [1:200] 0.971 0.243 0.139 0.588 0.275 ... $ Nnode : int 100 $ node.label : chr [1:100] \"OROOT\" \"\" \"\" \"\" ... $ tip.label : chr [1:101] \"MAG_94\" \"MAG_64\" \"MAG_43\" \"MAG_16\" ... - attr(*, \"class\")= chr \"phylo\" - attr(*, \"order\")= chr \"cladewise\" read in metadata \u00b6 metadata_df <- read.table ( path2metadata_file , header = TRUE , sep = \"\\t\" , as.is = TRUE , stringsAsFactors = FALSE ) head ( metadata_df ) A data.frame: 6 \u00d7 5 MAG_ID Length Completion Redundancy GC_Content <chr> <int> <dbl> <dbl> <dbl> MAG_1 2495192 90.65 6.5 38.80 MAG_10 722913 56.12 0.0 49.36 MAG_100 705754 60.43 4.3 29.17 MAG_101 2446458 97.12 0.7 44.02 MAG_102 2626036 95.68 4.3 46.83 MAG_11 1024210 79.14 2.9 36.51 associate metadata and tree \u00b6 p <- ggtree ( tree ) + theme_tree2 () p <- p %<+% metadata_df + geom_tiplab ( size = 1 , offset = 0.5 , align = TRUE , linesize = .2 , hjust = -0.1 ) + geom_tippoint ( aes ( size = Length ), alpha = 0.5 ) data_df <- data.frame ( id = tree $ tip.label , data = metadata_df[metadata_df $ MAG_ID %in% tree $ tip.label , c ( 'Length' , 'Completion' , 'Redundancy' , 'GC_Content' ) ] ) head ( data_df ) Warning message: \u201cDuplicated aesthetics after name standardisation: size\u201d A data.frame: 6 \u00d7 5 id data.Length data.Completion data.Redundancy data.GC_Content <fct> <int> <dbl> <dbl> <dbl> MAG_94 2495192 90.65 6.5 38.80 MAG_64 722913 56.12 0.0 49.36 MAG_43 705754 60.43 4.3 29.17 MAG_16 2446458 97.12 0.7 44.02 MAG_32 2626036 95.68 4.3 46.83 MAG_70 1024210 79.14 2.9 36.51 plot \u00b6 p <- facet_plot ( p + xlim_tree ( 3.5 ), panel = \"Completion\" , data = data_df , geom = geom_segment , aes ( x = 0 , xend = Completion , y = y , yend = y ), size = 1 , alpha = .5 ) p <- facet_plot ( p , panel = \"Redundancy\" , data = data_df , geom = geom_segment , aes ( x = 0 , xend = Redundancy , y = y , yend = y ), size = 1 , alpha = .5 ) p <- facet_plot ( p , panel = \"GC Content\" , data = data_df , geom = geom_point , aes ( x = GC_Content ), alpha = .5 , size = 1 ) p <- p + theme ( legend.position = 'left' ) + scale_colour_gradient ( low = \"blue\" , high = \"red\" ) #scale_color_gradient2(midpoint = mid, low = \"blue\", mid = \"white\", high = \"red\", space = \"Lab\" )# library ( grid ) gt = ggplot_gtable ( ggplot_build ( p )) gt $ widths[7] = 3 * gt $ widths[7] # increase the width of Tree panel grid.draw ( gt ) # save the plot ggsave ( filename = \"MAGstats.png\" , plot = last_plot (), path = \"./\" , scale = 1 , width = 297 , height = 210 , units = \"mm\" , dpi = 300 , limitsize = FALSE )","title":"MAGstats"},{"location":"MAGstats/#magstats","text":"A workflow to visualize the completeness and redundancy of your MAGs.","title":"MAGstats"},{"location":"MAGstats/#beginners-guide","text":"To visualize the completeness and reduduancy of your MAG, you need to get two files ready ( example_data ): A newick tree file ( MAG_tree.nwk ) A metadata file ( MAG_metadata.tsv ) The metadata file must contain these columns in order: MAG_ID Length Completion Redundancy GC_Content , and is tab-delimited. You can launch this jupyter notebook using binder by clicking , and upload your files to the example_data folder via the upload button in your project directory (where the index.ipynb locates). You probably need to modify these two lines to adapt to your file names in the first code block before running through all the codes: nwk_file <- \"MAG_tree.nwk\" bin_metadata_file <- \"MAG_metadata.tsv\"","title":"Beginners Guide"},{"location":"MAGstats/#how-to-generate-input-files","text":"For the tree file, you can use GToTree to extract single-copy marker genes and to get the concatenated multiple sequence alignements. Then use RAxML-NG to build the maximum-likelihood phylogenomic tree. GToTree also generate a tree file by running fasttree . For the metadata file, you can get it via checkM or anvio , and format it using Excel and export it as tsv. If everything works well, you will get something like this:","title":"How to generate input files"},{"location":"MAGstats/#read-in-mag-tree","text":"data_folder <- \"./example_data\" nwk_file <- \"MAG_tree.nwk\" bin_metadata_file <- \"MAG_metadata.tsv\" path2nwk_file <- paste ( data_folder , nwk_file , sep = \"/\" ) path2metadata_file <- paste ( data_folder , bin_metadata_file , sep = \"/\" ) path2nwk_file path2metadata_file './example_data/MAG_tree.nwk' './example_data/MAG_metadata.tsv'","title":"Read in MAG tree"},{"location":"MAGstats/#load-packages","text":"library ( \"RColorBrewer\" ) library ( 'ggplot2' ) library ( 'ggtree' ) ggtree v1.14.6 For help: https://guangchuangyu.github.io/software/ggtree If you use ggtree in published research, please cite the most appropriate paper(s): - Guangchuang Yu, David Smith, Huachen Zhu, Yi Guan, Tommy Tsan-Yuk Lam. ggtree: an R package for visualization and annotation of phylogenetic trees with their covariates and other associated data. Methods in Ecology and Evolution 2017, 8(1):28-36, doi:10.1111/2041-210X.12628 - Guangchuang Yu, Tommy Tsan-Yuk Lam, Huachen Zhu, Yi Guan. Two methods for mapping and visualizing associated data on phylogeny using ggtree. Molecular Biology and Evolution 2018, accepted. doi: 10.1093/molbev/msy194","title":"load packages"},{"location":"MAGstats/#read-in-tree","text":"tree <- read.tree ( path2nwk_file ) str ( tree ) List of 5 $ edge : int [1:200, 1:2] 102 103 103 104 104 102 105 106 107 108 ... $ edge.length: num [1:200] 0.971 0.243 0.139 0.588 0.275 ... $ Nnode : int 100 $ node.label : chr [1:100] \"OROOT\" \"\" \"\" \"\" ... $ tip.label : chr [1:101] \"MAG_94\" \"MAG_64\" \"MAG_43\" \"MAG_16\" ... - attr(*, \"class\")= chr \"phylo\" - attr(*, \"order\")= chr \"cladewise\"","title":"read in tree"},{"location":"MAGstats/#read-in-metadata","text":"metadata_df <- read.table ( path2metadata_file , header = TRUE , sep = \"\\t\" , as.is = TRUE , stringsAsFactors = FALSE ) head ( metadata_df ) A data.frame: 6 \u00d7 5 MAG_ID Length Completion Redundancy GC_Content <chr> <int> <dbl> <dbl> <dbl> MAG_1 2495192 90.65 6.5 38.80 MAG_10 722913 56.12 0.0 49.36 MAG_100 705754 60.43 4.3 29.17 MAG_101 2446458 97.12 0.7 44.02 MAG_102 2626036 95.68 4.3 46.83 MAG_11 1024210 79.14 2.9 36.51","title":"read in metadata"},{"location":"MAGstats/#associate-metadata-and-tree","text":"p <- ggtree ( tree ) + theme_tree2 () p <- p %<+% metadata_df + geom_tiplab ( size = 1 , offset = 0.5 , align = TRUE , linesize = .2 , hjust = -0.1 ) + geom_tippoint ( aes ( size = Length ), alpha = 0.5 ) data_df <- data.frame ( id = tree $ tip.label , data = metadata_df[metadata_df $ MAG_ID %in% tree $ tip.label , c ( 'Length' , 'Completion' , 'Redundancy' , 'GC_Content' ) ] ) head ( data_df ) Warning message: \u201cDuplicated aesthetics after name standardisation: size\u201d A data.frame: 6 \u00d7 5 id data.Length data.Completion data.Redundancy data.GC_Content <fct> <int> <dbl> <dbl> <dbl> MAG_94 2495192 90.65 6.5 38.80 MAG_64 722913 56.12 0.0 49.36 MAG_43 705754 60.43 4.3 29.17 MAG_16 2446458 97.12 0.7 44.02 MAG_32 2626036 95.68 4.3 46.83 MAG_70 1024210 79.14 2.9 36.51","title":"associate metadata and tree"},{"location":"MAGstats/#plot","text":"p <- facet_plot ( p + xlim_tree ( 3.5 ), panel = \"Completion\" , data = data_df , geom = geom_segment , aes ( x = 0 , xend = Completion , y = y , yend = y ), size = 1 , alpha = .5 ) p <- facet_plot ( p , panel = \"Redundancy\" , data = data_df , geom = geom_segment , aes ( x = 0 , xend = Redundancy , y = y , yend = y ), size = 1 , alpha = .5 ) p <- facet_plot ( p , panel = \"GC Content\" , data = data_df , geom = geom_point , aes ( x = GC_Content ), alpha = .5 , size = 1 ) p <- p + theme ( legend.position = 'left' ) + scale_colour_gradient ( low = \"blue\" , high = \"red\" ) #scale_color_gradient2(midpoint = mid, low = \"blue\", mid = \"white\", high = \"red\", space = \"Lab\" )# library ( grid ) gt = ggplot_gtable ( ggplot_build ( p )) gt $ widths[7] = 3 * gt $ widths[7] # increase the width of Tree panel grid.draw ( gt ) # save the plot ggsave ( filename = \"MAGstats.png\" , plot = last_plot (), path = \"./\" , scale = 1 , width = 297 , height = 210 , units = \"mm\" , dpi = 300 , limitsize = FALSE )","title":"plot"},{"location":"editing_this_site/","text":"Editing this Site \u00b6 All the docs on this site are written in markdown ( .md files) and built into an html site by mkdocs . If you want to edit any of these documents, you can make changes to the corresponding markdown file (or add a new one), and then edit the mkdocs configuration to make sure the file gets built into html. Read on for instructions! The first time you clone a repo with a mkdocs submodule: \u00b6 If you want to edit the docs, you'll need to grab the mkdocs-material-dib submodule. If you're cloning the repo for the first time: git clone --recursive https://github.com/speeding-up-science-workshops/speeding-up-science recursive will pull the submodule as well as the main git repo. However, if you already have the repo, you'll want to pull down submodule like this: git submodule update --init Installing the tools \u00b6 We recommend conda for tool installation. conda install -c conda-forge mkdocs conda install -c conda-forge ghp-import Where are the docs? \u00b6 Each page on the website is a markdown document in the docs folder. These are organized by the navigation ( nav ) text in the mkdocs.yml file, which sits in the main directory. By looking at the mkdocs.yml file, you can find the name of the markdown file you want to edit. Updating an Existing Page \u00b6 If you're updating a file that already exists, start by making edits to the appropriate markdown file. Then, you'll want to check that the markdown you wrote will be rendered properly. Assuming you've installed mkdocs (above), you build the markdown into html like so: mkdocs build And then build a local site like so: mkdocs serve The site will now be rendered on your local computer (viewable in your web browser at the link that will come up on your screen with a successful mkdocs serve , like http://127.0.0.1:8000/ ) and you can continue to make changes to your md file until it looks right. Stop the mkdocs serve by using Ctrl-C . When you're finished, commit your changes as you normally would, e.g.: git add <myfile.md> git commit -m \"some useful commit message\" And then build the site one last time and push to the gh-pages branch like so: mkdocs build ghp-import site -p Adding a New Page \u00b6 If you want to add a new page, you'll need to add that file to the file navigation in the mkdocs.yml file. First go look at the nav sectino in mkdocs.yml while looking at the built site and figure out what section you'd like to put your new page in. Then add your page to the nav like so: - 'New-Title`: new-page.md Then, you'll need to go through the same steps as above, for Updating an Existing Page . In short: make changes to md file mkdocs build to build html site mkdocs serve to view page and navigation repeat the above steps until satisfied git commit (and git push ) your changes mkdocs build and then ghp-import site -p to update the website Troubleshooting \u00b6 If you see errors during mkdocs build or mkdocs serve , the likely culprit is improper formatting of the nav section in the mkdocs.yml file. Yaml is sensitive to spacing, quotes, etc! Check out the working pages and make your entry look like those! Any other issues? Submit an issue on github!","title":"Editing This Site"},{"location":"editing_this_site/#editing-this-site","text":"All the docs on this site are written in markdown ( .md files) and built into an html site by mkdocs . If you want to edit any of these documents, you can make changes to the corresponding markdown file (or add a new one), and then edit the mkdocs configuration to make sure the file gets built into html. Read on for instructions!","title":"Editing this Site"},{"location":"editing_this_site/#the-first-time-you-clone-a-repo-with-a-mkdocs-submodule","text":"If you want to edit the docs, you'll need to grab the mkdocs-material-dib submodule. If you're cloning the repo for the first time: git clone --recursive https://github.com/speeding-up-science-workshops/speeding-up-science recursive will pull the submodule as well as the main git repo. However, if you already have the repo, you'll want to pull down submodule like this: git submodule update --init","title":"The first time you clone a repo with a mkdocs submodule:"},{"location":"editing_this_site/#installing-the-tools","text":"We recommend conda for tool installation. conda install -c conda-forge mkdocs conda install -c conda-forge ghp-import","title":"Installing the tools"},{"location":"editing_this_site/#where-are-the-docs","text":"Each page on the website is a markdown document in the docs folder. These are organized by the navigation ( nav ) text in the mkdocs.yml file, which sits in the main directory. By looking at the mkdocs.yml file, you can find the name of the markdown file you want to edit.","title":"Where are the docs?"},{"location":"editing_this_site/#updating-an-existing-page","text":"If you're updating a file that already exists, start by making edits to the appropriate markdown file. Then, you'll want to check that the markdown you wrote will be rendered properly. Assuming you've installed mkdocs (above), you build the markdown into html like so: mkdocs build And then build a local site like so: mkdocs serve The site will now be rendered on your local computer (viewable in your web browser at the link that will come up on your screen with a successful mkdocs serve , like http://127.0.0.1:8000/ ) and you can continue to make changes to your md file until it looks right. Stop the mkdocs serve by using Ctrl-C . When you're finished, commit your changes as you normally would, e.g.: git add <myfile.md> git commit -m \"some useful commit message\" And then build the site one last time and push to the gh-pages branch like so: mkdocs build ghp-import site -p","title":"Updating an Existing Page"},{"location":"editing_this_site/#adding-a-new-page","text":"If you want to add a new page, you'll need to add that file to the file navigation in the mkdocs.yml file. First go look at the nav sectino in mkdocs.yml while looking at the built site and figure out what section you'd like to put your new page in. Then add your page to the nav like so: - 'New-Title`: new-page.md Then, you'll need to go through the same steps as above, for Updating an Existing Page . In short: make changes to md file mkdocs build to build html site mkdocs serve to view page and navigation repeat the above steps until satisfied git commit (and git push ) your changes mkdocs build and then ghp-import site -p to update the website","title":"Adding a New Page"},{"location":"editing_this_site/#troubleshooting","text":"If you see errors during mkdocs build or mkdocs serve , the likely culprit is improper formatting of the nav section in the mkdocs.yml file. Yaml is sensitive to spacing, quotes, etc! Check out the working pages and make your entry look like those! Any other issues? Submit an issue on github!","title":"Troubleshooting"},{"location":"setting_up_mkdocs/","text":"Setting up MkDocs in a new repo \u00b6 In your repo: Add mkdocs-material-dib as a submodule: git submodule add https://github.com/dib-lab/mkdocs-material-dib.git echo \"site/\" >> .gitignore Commit: git add .gitmodules .gitignore mkdocs-material-dib git commit .gitmodules .gitignore mkdocs-material-dib -m 'Add mkdocs-material-dib submodule' Install mkdocs and ghp-import if necessary: \u00b6 conda install -c conda-forge mkdocs conda install -c conda-forge ghp-import Edit site info and create docs \u00b6 Grab a mkdocs.yml file that you can edit. For example, this is the one for a metatranscriptomics workshop we taught in Nov 2018. To see what that site looks like, go here . wget https://raw.githubusercontent.com/ngs-docs/2018-cicese-metatranscriptomics/master/mkdocs.yml Edit the info in mkdocs.yml to reflect your repo name and address, color, and sidebar navigation ( nav ). You'll also see that you can change the names for your docs directory and built web pages, but I assume here that they are docs and site , respectively. Make a docs directory where you'll add the markdown docs for the website. Add a simple hello world or similar md file to start. mkdir -p docs echo '# Hello World' > docs/index.md Deploy the site \u00b6 Go to Settings in your repo, and enable Github Pages for your repository. In your repo, build the site: mkdocs build View your site locally: mkdocs serve Push your changes to gh-pages : ghp-import site -p Check your Github Pages URL for your simple md file: https://<repo-owner>.github.io/<repo-name> Continue to edit your docs, using mkdocs build to build the html version of the site, and ghp-import to push to gh-pages . Voila! The first time you clone a repo with a mkdocs submodule: \u00b6 (for example, if you set this up on a different computer, but want to edit the docs) If you want to edit the docs, you'll need to grab the mkdocs-material-dib submodule. If cloning the repo for the first time: git clone --recursive https://github.com/<repo-owner>/<repo-name>.git recursive will pull the submodule as well as the main git repo. If you already have the repo, and need to pull in the submodule: git submodule update --init For more details, follow the instructions here","title":"Setting Up mkdocs"},{"location":"setting_up_mkdocs/#setting-up-mkdocs-in-a-new-repo","text":"In your repo: Add mkdocs-material-dib as a submodule: git submodule add https://github.com/dib-lab/mkdocs-material-dib.git echo \"site/\" >> .gitignore Commit: git add .gitmodules .gitignore mkdocs-material-dib git commit .gitmodules .gitignore mkdocs-material-dib -m 'Add mkdocs-material-dib submodule'","title":"Setting up MkDocs in a new repo"},{"location":"setting_up_mkdocs/#install-mkdocs-and-ghp-import-if-necessary","text":"conda install -c conda-forge mkdocs conda install -c conda-forge ghp-import","title":"Install mkdocs and ghp-import if necessary:"},{"location":"setting_up_mkdocs/#edit-site-info-and-create-docs","text":"Grab a mkdocs.yml file that you can edit. For example, this is the one for a metatranscriptomics workshop we taught in Nov 2018. To see what that site looks like, go here . wget https://raw.githubusercontent.com/ngs-docs/2018-cicese-metatranscriptomics/master/mkdocs.yml Edit the info in mkdocs.yml to reflect your repo name and address, color, and sidebar navigation ( nav ). You'll also see that you can change the names for your docs directory and built web pages, but I assume here that they are docs and site , respectively. Make a docs directory where you'll add the markdown docs for the website. Add a simple hello world or similar md file to start. mkdir -p docs echo '# Hello World' > docs/index.md","title":"Edit site info and create docs"},{"location":"setting_up_mkdocs/#deploy-the-site","text":"Go to Settings in your repo, and enable Github Pages for your repository. In your repo, build the site: mkdocs build View your site locally: mkdocs serve Push your changes to gh-pages : ghp-import site -p Check your Github Pages URL for your simple md file: https://<repo-owner>.github.io/<repo-name> Continue to edit your docs, using mkdocs build to build the html version of the site, and ghp-import to push to gh-pages . Voila!","title":"Deploy the site"},{"location":"setting_up_mkdocs/#the-first-time-you-clone-a-repo-with-a-mkdocs-submodule","text":"(for example, if you set this up on a different computer, but want to edit the docs) If you want to edit the docs, you'll need to grab the mkdocs-material-dib submodule. If cloning the repo for the first time: git clone --recursive https://github.com/<repo-owner>/<repo-name>.git recursive will pull the submodule as well as the main git repo. If you already have the repo, and need to pull in the submodule: git submodule update --init For more details, follow the instructions here","title":"The first time you clone a repo with a mkdocs submodule:"}]}